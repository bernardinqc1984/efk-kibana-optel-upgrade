# Fluentd Configuration for Kubernetes Monitoring
# This configuration collects logs from all Kubernetes pods and sends them to ElasticSearch

fluentd.conf: |
  <source>
    @type tail
    @id in_tail_container_logs
    path /var/log/containers/*.log
    pos_file /var/log/fluentd-containers.log.pos
    tag kubernetes.*
    read_from_head true
    <parse>
      @type json
      time_format %Y-%m-%dT%H:%M:%S.%NZ
    </parse>
  </source>

  # Add Kubernetes metadata to logs
  <filter kubernetes.**>
    @type kubernetes_metadata
    @id filter_kube_metadata
    kubernetes_url "#{ENV['FLUENT_FILTER_KUBERNETES_URL'] || 'https://' + ENV.fetch('KUBERNETES_SERVICE_HOST') + ':' + ENV.fetch('KUBERNETES_SERVICE_PORT') + '/api'}"
    verify_ssl "#{ENV['KUBERNETES_VERIFY_SSL'] || true}"
    ca_file "#{ENV['KUBERNETES_CA_FILE']}"
    skip_labels false
    skip_container_metadata false
    skip_master_url false
    skip_namespace_metadata false
  </filter>

  # Add cluster information and parse structured logs
  <filter kubernetes.**>
    @type record_transformer
    <record>
      cluster_name "monitoring-cluster"
      timestamp ${time}
    </record>
  </filter>

  # Send to ElasticSearch
  <match kubernetes.**>
    @type elasticsearch
    @id out_es
    @log_level info
    include_tag_key true
    host "#{ENV['FLUENT_ELASTICSEARCH_HOST'] || 'elasticsearch'}"
    port "#{ENV['FLUENT_ELASTICSEARCH_PORT'] || '9200'}"
    scheme "#{ENV['FLUENT_ELASTICSEARCH_SCHEME'] || 'http'}"
    ssl_verify "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERIFY'] || 'false'}"
    reload_connections false
    reconnect_on_error true
    reload_on_failure true
    log_es_400_reason false
    logstash_prefix fluentd
    logstash_format true
    index_name fluentd
    type_name _doc
    <buffer>
      flush_thread_count 8
      flush_interval 5s
      chunk_limit_size 2M
      queue_limit_length 32
      retry_max_interval 30
      retry_forever true
    </buffer>
  </match>
